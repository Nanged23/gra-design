from openai import OpenAI
import os
from dotenv import load_dotenv

load_dotenv()


async def get_summary(a):
    try:
        client = OpenAI(
            api_key=os.getenv('MOONSHOT_API_KEY'),
            base_url="https://api.moonshot.cn/v1",
        )
        str1 = f"请以专业的、客观的风格分析以下博客文章的内容，无论文章类型，尝试提取其核心主题和主要信息。如果文章是观点或结论类，请重点总结其核心观点和结论；如果文章是日记、散文等其他类型，请提炼文章所表达的情感、经历或事件。用简洁的语言概括文章的主题。总结的字数控制在 180 字以内。{a}"
        completion = client.chat.completions.create(
            model="moonshot-v1-8k",
            messages=[
                {"role": "system",
                 "content": "你是一位[擅长内容总结]的人工智能助手，你更擅长中文和英文的对话。你会为用户提供安全，有帮助，准确的回答。同时，你会拒绝一切涉及恐怖主义，种族歧视，黄色暴力等问题的回答。"},
                {"role": "user", "content": str1}
            ],
            temperature=0.3,
        )
        return completion.choices[0].message.content
    except Exception as e:
        raise e


if __name__ == "__main__":
    a = """
    输入结构与上下文处理
    • 内置推理 vs. 需要提示激发的推理
    O1 系列模型带有“内置的链式思考推理”功能，也就是说，它们在内部会自动进行多步推理，而无需在提示中特别引导。相比之下，GPT-4o 通常需要外部指令（例如“让我们一步步地思考”）来激发更深入的多步推理。如果使用 O1/O3，只要直接给出问题本身，模型就会自动进行深度分析。
    
    • 对外部信息的需求
    GPT-4o 在某些部署中可能具备广泛的知识库和对工具的访问权限（如浏览、插件、图像识别等），能处理各种主题；相比之下，O1 模型在其训练焦点之外的知识面更窄。例如，O1-preview 在推理任务中表现出色，但却无法回答有关自身的问题，因为缺乏相关的知识上下文。因此，当你使用 O1/O3-mini 处理超出常识范围的任务时，务必在提示中包含必要的背景信息或上下文，不要假设模型知道小众领域的事实。GPT-4o 可能已经了解某个法律先例或冷门细节，但 O1 可能需要你提供这些文本或数据。
    
    • 上下文长度
    这些推理模型拥有非常大的上下文窗口。O1 支持最长 128k 个 token 的输入，O3-mini 可接受最多 200k 个 token（且可输出高达 100k 个 token），这超过了 GPT-4o 的上下文长度。这样，你可以将更大规模的案例文件或数据集直接输入 O1/O3。在进行提示工程时，若输入非常庞大，应有条理地组织信息（使用章节、要点或标题），方便模型定位。虽然 GPT-4o 和 O1 都能处理长提示，但 O1/O3 更大的容量意味着你可一次性提供更详细的上下文——对复杂分析很有用。
    
    推理能力与逻辑推导
    • 推理深度
    O1 和 O3-mini 专门针对“方法性、多步推理”进行了优化，可以在回答之前进行更多层次的分析，从而在复杂任务上给出更精确的结果。例如，O1-preview 在一个较难的数学考试（AIME）中能够解对 83% 的题目，而 GPT-4o 仅能解对 13%，这反映了 O1 在特定专业领域中更出色的逻辑推导能力。这些模型会在内部执行链式思考并自我检查。GPT-4o 本身也很强大，但若不进行显式的逐步引导，对非常复杂的问题往往不会分析得那么深入，而 O1 则能更容易发现这种复杂性并做出正确推理。
    
    • 复杂任务 vs. 简单任务
    由于 O1 系列模型默认会进行深度推理，因此在需要多步推理（如多方面分析、长论证）的复杂问题上，它们表现尤为出色。一些研究表明，当任务需要 5 步或以上推理时，O1-mini 或 O3 这类推理模型比 GPT-4 的准确率高出 16% 以上。然而，这也意味着对于非常简单的查询，O1 可能会“想得太多”。研究发现，在只需少于 3 步推理的简单任务上，O1 过度推理反而会拖累表现，GPT-4o 更可能迅速给出直接答案，而 O1 有可能产生不必要的冗长分析。换言之，O1 的优点在于更好地处理复杂度，而对于琐碎的问答，它在效率上可能稍逊。
    
    • 逻辑推导风格
    在解谜、演绎推理或逐步分解问题时，GPT-4o 通常需要我们在提示里“强制”它逐步进行推理，否则它可能迅速跳到结论。O1/O3 则不然：它们在内部会模拟对话或“草稿思维”。对用户而言，O1 的最终答案往往更有理有据，不易出现逻辑漏洞，因为它在内部做了多步验证。就提示角度来说，一般不需要特意告诉 O1 “请解释或检查你的逻辑”，它会自动这么做；如果是 GPT-4o，你可能会在提示中加入“先列出假设，然后得出结论”一类的引导。对 O1 来说，这些指令往往是多余甚至会产生干扰。
    
    响应特征与输出优化
    • 细节与冗长度
    因为进行的是深入推理，O1 和 O3-mini 在回答复杂问题时常会生成细致且结构化的答案。例如，O1 可能将数学解题分解为多个步骤，或针对一个战略方案逐步阐述理由；而 GPT-4o 在默认情况下往往更简练，或只提供概览，除非在提示中要求它进一步展开。因此，在提示工程上，O1 的回答可能更长、更技术化。你可以通过指令来控制它的回答长度和形式——如果你希望它简明扼要，就要明确告知（对 GPT-4 也同理）；如果你希望输出一步步的解释，GPT-4o 需要被特别指示，O1 通常只要被要求，就会开心地给出（而且事实上它内部总是在这么做）。
    
    • 准确性与自我检查
    这些推理模型具备一定的自我事实核查机制。OpenAI 指出，O1 在生成响应的过程中更善于发现并纠正错误，因此在复杂回答上有更高的准确率。虽然 GPT-4o 一般也相当准确，但在没有提示的情况下，它有时会自信地给出错误信息或幻觉出事实；O1 通过“思维”过程减少了这一风险。实践表明，在棘手的问题上，O1 的回答通常更少出现明显错误，而 GPT-4o 往往需要一些提示技巧（例如让它批评或验证自己的答案）才能达到同样的把握度。因此，如果使用 O1/O3 直接提问，就可在复杂任务上获得更可靠的结果，而对 GPT-4o 则可能要加上类似“请检查答案是否与上述事实一致”的指令。不过，任何模型都非完美，对于关键性的答案仍需用户核实。
    
    • 速度与成本
    O1 模型的一个显著区别在于：它的推理更深入，但响应速度更慢、费用更高。O1 Pro 甚至为长时间查询配备了进度条。而 GPT-4o 在处理一般查询时速度更快。O3-mini 则面向更快且更省成本的推理场景——它的每个 token 费用比 O1 或 GPT-4o 都要低，延迟也更短。但由于 O3-mini 的模型规模更小，虽然在 STEM 领域推理表现不俗，但在通用知识或极度复杂的推理上可能不及 O1 或 GPT-4。因此，在进行响应性能优化的提示工程时，需要在推理深度与速度之间做平衡：O1 可能答得更深入，但也更慢。如果延迟是重点、任务并不需要极度复杂的推理，O3-mini 或 GPT-4o 可能更合适。OpenAI 的官方建议是，GPT-4o 在大多数场景下依然是“最佳通用选择”，而 O1 则适合在诸如战略、数学、编程等高难度任务中发力。总之，要针对任务选择合适的模型；若你选择 O1，要心理准备它输出更慢，并相应调整用户预期或系统的超时时间。
    """
    print(get_summary(a))
